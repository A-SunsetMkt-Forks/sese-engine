# sese-engine设计文档

![结构.png](结构.png)

sese-engine主要分为6个部分: 

- 爬虫程序

    它24小时都在上网。是现代大学生的榜样。

- 反向索引整理器

    它将爬虫程序收集到的关键词整理成反向索引。

- 反向链接统计器

    它根据各个域名的出站链接为域名计算权重。

- 本地存储

    它负责把收集到的各种信息写到硬盘上。

- 前端服务器
 
    它接收用户的请求并返回搜索结果。

- 用户

    它通常是1个人类。但也可以不是。


## 爬虫程序

爬虫程序本质上是一个无限BFS程序。

把每个URL当作一个节点，URL到另外一个URL的`a`标签当作边，这就构成了一张有向图。它就是在这个图上，从配置里的入口开始跑BFS。

不过这个BFS的队列很容易就会爆内存，所以在每把1距离的节点全都访问完时，就会把队列中的按一个特殊的规则丢弃一些。

丢弃的规则大概是这样的: 

1. 如果队列太长，随机加权丢弃一些。权重是根据网站的已访问次数、语种、反向链接数量等计算出来的。
2. 如果单个域名的URL太多，随机丢弃一些。
3. 如果HTTP(没有S)的URL太多，随机丢弃一些。
4. 如果无反向链接的域名的URL太多，随机丢弃一些。

当URL被访问到时，会将这个网页的信息还有域名的信息实时储存在硬盘上，接下来把这个网页中的词频塞到发送队列里，给反向索引整理器处理。


## 反向索引整理器

反向索引整理器就是用来生成反向索引的。

它接收来自爬虫程序的输入，用本地HTTP服务器的形式和爬虫程序做进程间通信。

反向索引就是每1个词对应n个相关的URL，而反向索引整理器收到的输入是每1个URL对应n个词。所以要把词和URL反过来，然后经过筛选、排序，最后写入本地存储中。

筛选的规则大概是这样的: 

1. 如果1个词对应的URL列表中包含同一个URL的https/http形态，有末尾斜杠/无末尾斜杠，就合并它们<small>(尽管实际内容可能不同)</small>。
2. 如果1个词对应的URL个数超过上限的1.1倍，就对这些URL计算一次权，权的值取决于那个词在URL中的词频以及URL的反向链接的个数。接下来，如果列表中来自相同域名的URL过多，就把每个超过的域名各自丢弃一些，再把总数丢弃到上限1倍。丢弃时总是丢弃权重最低的部分。
3. 此外，每个词即使不满足`2`的条件，也有2%的机率强制进入`2`。


## 反向链接统计器

反向链接统计器用于统计URL的繁荣度。

这是一个定时任务，很吃CPU和内存，所以需要定时在半夜执行。

繁荣度的作用是这样，一个URL越繁荣，在搜索结果时就越优先排在前面，也不容易被反向索引整理器丢掉。计算方法是，其他域名引用这个URL越多，这个URL的繁荣度就越高。

反向链接统计器会遍历本地存储中所有域名的出站链接，然后在对应的URL上做累加，最后将高繁荣度的URL写入JSON文件。

但是理论上URL有无穷多个，如何用4G内存把它们数完呢，这个算法大概是这样: 

1. 给URL建一个空的树，规则是每多一个斜线就变成它的子节点，比如`github.com/RimoChan`是`github.com`的子节点。
2. 把反向链接随机打乱。
3. 读反向链接，每读1个URL，就增加它和它所有的祖先节点的值，如果它们不在树上就新建节点。
4. 当树的大小太大<small>(比如内存快用完)</small>时，改变策略，每次读取还是会增加节点的值，但是不会新建节点。

这样建树可以大体掌握反向链接的分布，实际需要用的时候再根据那个URL的各个祖先的值去估计就好了。


## 本地存储

本地存储是直接写在文件系统里的。

本地存储不是一个独立服务，它是组件，因此不是进程安全的。

它为其他各个组件提供一个通用的k-v存取接口。此外也定义了一些特殊的压缩和序列化的方法。


## 前端服务器

前端服务器是用户直接与搜索引擎交互的服务器。

前端服务器接收来自用户的查询，将一个查询进行分词、找索引、筛选、排序、获取摘要，之后把搜索结果返回给UI用于渲染。

前端服务器本身不包括UI，UI在[YunYouJun/sese-engine-ui](https://github.com/YunYouJun/sese-engine-ui)，是由GitHub Pages提供的服务。


## 用户

用户一般是智人种的动物，但也可以是狗等具有一定智能的对象。

用户通常会在宜居环境中自动繁殖，不需要特意部署。
